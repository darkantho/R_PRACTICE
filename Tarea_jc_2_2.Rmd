---
Materia: "M?todos de Anal?tica para la Industria "
Autor: "Juan Carlos letechi Mor?n"
Fecha: "1/20/2021"
output: pdf_document
---

```{r setup, include=FALSE}
rm(list=ls())

knitr::opts_chunk$set(echo = TRUE)
```

```{r paquetes}
library("chron")
library("e1071")
library("MASS")
library("klaR")
library("lattice")
library("ggplot2")
library("caret")
library("readr")
```

# Tarea pr?ctica 1
## Tema 1


Se procede a importar el archivo FlightDelays.csv.
```{r datos ,message=FALSE, warning=FALSE}
dataset_tema_1 <- read_csv("/home/anthony/Documents/jc_IA/FlightDelays.csv")
```
**Se realiza un arreglo de las variables.**

```{r arreglos}
# dataset_tema_1$carrier<-as.factor(dataset_tema_1$carrier)
# dataset_tema_1$dest<-as.factor(dataset_tema_1$dest)
# dataset_tema_1$origin<-as.factor(dataset_tema_1$origin)
dataset_tema_1$dayweek<-ifelse(dataset_tema_1$dayweek == 7| dataset_tema_1$dayweek==1, 1, 0)
dataset_tema_1$delay<-ifelse(dataset_tema_1$delay=="ontime", 0, 1)
dataset_tema_1$delay<-as.factor(dataset_tema_1$delay)
```

**Se categorizan los tiempos de reuni?n.**

```{r for_1}
vector_cat<-c()
contador<-0
for (i in dataset_tema_1$schedtime){
   contador<-contador+1
   varia<-unlist(strsplit(toString(i), ""))
   if(length(varia)==4){
      vector_cat[contador]<-as.integer(paste(varia[1:2], collapse=""))
   }else{
      vector_cat[contador]<-as.integer(varia[1])
   }
}
dataset_tema_1$schedtime<-vector_cat
```

**Se categorizan los vuelos de deeptime.**

```{r for_2}
vector_cat_2<-c()
contador<-0
for (i in dataset_tema_1$deptime){
   contador<-contador+1
   varia<-unlist(strsplit(toString(i), ""))
   if(length(varia)==4){
      vector_cat_2[contador]<-as.integer(paste(varia[1:2], collapse=""))
   }else{
      vector_cat_2[contador]<-as.integer(varia[1])
   }
}
dataset_tema_1$deptime<-vector_cat_2
```

**Se recorta el dataset por los vuelos entre 6:00 am a 22:00 pm.**
```{r dataset_final}
dataset_tema_1_1=subset(dataset_tema_1,dataset_tema_1$deptime>=6 & dataset_tema_1$deptime<=22)

dataset_tema_1_1$deptime<-as.factor(dataset_tema_1_1$deptime)
# dataset_tema_1_1$schedtime<-as.factor(dataset_tema_1_1$schedtime)


```

### a) Particionar los datos en 70% para entrenamiento del modelo y 30% para prueba.

```{r particion}
particion = createDataPartition(dataset_tema_1_1$delay,p=0.7,list=FALSE,times=1)
X_TRAIN = dataset_tema_1_1[particion,]
Y_TRAIN=X_TRAIN$delay
X_TRAIN=subset(X_TRAIN,select=-delay)
X_TRAIN=subset(X_TRAIN,select=-deptime)
X_TEST =dataset_tema_1_1[-particion,]
Y_TEST=X_TEST$delay
X_TEST=subset(X_TEST,select=-delay)
X_TEST=subset(X_TEST,select=-deptime)
```

### b) Para cada variable entrene el modelo de bosque aleatorio con una sola variable. Utilice los datos de entrenamiento.

**Variable schedtime:**

```{r m1 ,message=FALSE, warning=FALSE}
m1<-train(x=subset(X_TRAIN,select=schedtime),y=Y_TRAIN,method = "rf",ntree=50,trControl = trainControl(method = "cv",number = 10))
m1$finalModel
prediccion1 = predict(m1,subset(X_TEST,select = schedtime))
acc1=confusionMatrix(prediccion1,Y_TEST)
```

**Variable carrier:**

```{r m2,message=FALSE, warning=FALSE}
m2<-train(x=subset(X_TRAIN,select=carrier),y=Y_TRAIN,method = "rf",ntree=50,trControl = trainControl(method = "cv",number = 10))
m2$finalModel
prediccion2 = predict(m2,subset(X_TEST,select = carrier))
acc2=confusionMatrix(prediccion2, Y_TEST)
```

<!-- variable deptime -->

<!-- ```{r m3} -->
<!-- m3<-train(x=subset(X_TRAIN,select=deptime),y=Y_TRAIN,method = "rf",ntree=50,trControl = trainControl(method = "cv",number = 10)) -->
<!-- m3$finalModel -->
<!-- prediccion3 = predict(m3, subset(X_TEST,select = deptime)) -->
<!-- acc3=confusionMatrix(prediccion3, Y_TEST) -->
<!-- ``` -->

**Variable dest:**

```{r m4,message=FALSE, warning=FALSE}
m4<-train(x=subset(X_TRAIN,select=dest),y=Y_TRAIN,method = "rf",ntree=50,trControl = trainControl(method = "cv",number = 10))
m4$finalModel
prediccion4 = predict(m4,subset(X_TEST,select = dest))
acc4=confusionMatrix(prediccion4, Y_TEST)
```

**Variable distance:**

```{r m5,message=FALSE, warning=FALSE}
m5<-train(x=subset(X_TRAIN,select=distance),y=Y_TRAIN,method = "rf",ntree=50,trControl = trainControl(method = "cv",number = 10))
m5$finalModel
prediccion5 = predict(m5,subset(X_TEST,select = distance))
acc5=confusionMatrix(prediccion5,Y_TEST)
```

**Variable date:**

```{r m6,message=FALSE, warning=FALSE}
m6<-train(x=subset(X_TRAIN,select=date),y=Y_TRAIN,method = "rf",ntree=50,trControl = trainControl(method = "cv",number = 10))
m6$finalModel
prediccion6 = predict(m6,subset(X_TEST,select = date))
acc6=confusionMatrix(prediccion6, Y_TEST)
```

**Variable flightnumber:**

```{r m7,message=FALSE, warning=FALSE}
m7<-train(x=subset(X_TRAIN,select=flightnumber),y=Y_TRAIN,method = "rf",ntree=50,trControl = trainControl(method = "cv",number = 10))
m7$finalModel
prediccion7 = predict(m7,subset(X_TEST,select = flightnumber))
acc7=confusionMatrix(prediccion7, Y_TEST)
```

**Variable origin:**

```{r m8,message=FALSE, warning=FALSE}
m8<-train(x=subset(X_TRAIN,select=origin),y=Y_TRAIN,method = "rf",ntree=50,trControl = trainControl(method = "cv",number = 10))
m8$finalModel
prediccion8 = predict(m8,subset(X_TEST,select = origin))
acc8=confusionMatrix(prediccion8, Y_TEST)
```


**Variable weather:**

```{r m9,message=FALSE, warning=FALSE}
m9<-train(x=subset(X_TRAIN,select=weather),y=Y_TRAIN,method = "rf",ntree=50,trControl = trainControl(method = "cv",number = 10))
m9$finalModel
prediccion9 = predict(m9, subset(X_TEST,select = weather))
acc9=confusionMatrix(prediccion9, Y_TEST)
```

**Variable dayweek:**

```{r m10,message=FALSE, warning=FALSE}
m10<-train(x=subset(X_TRAIN,select=dayweek),y=Y_TRAIN,method = "rf",ntree=50,trControl = trainControl(method = "cv",number = 10))
m10$finalModel
prediccion10 = predict(m10,subset(X_TEST,select = dayweek))
acc10=confusionMatrix(prediccion10, Y_TEST)
```

**Variable daymonth:**

```{r m11,message=FALSE, warning=FALSE}
m11<-train(x=subset(X_TRAIN,select=daymonth),y=Y_TRAIN,method = "rf",ntree=50,trControl = trainControl(method = "cv",number = 10))
m11$finalModel
prediccion11 = predict(m11,subset(X_TEST,select = daymonth))
acc11=confusionMatrix(prediccion11, Y_TEST)
```

**Variable tailnu:**

```{r m12,message=FALSE, warning=FALSE}
m12<-train(x=subset(X_TRAIN,select=tailnu),y=Y_TRAIN,method = "rf",ntree=50,trControl = trainControl(method = "cv",number = 10))
m12$finalModel
prediccion12 = predict(m12,subset(X_TEST,select = tailnu))
acc12=confusionMatrix(prediccion12, Y_TEST)
```
### c) Identifique el modelo con el menor error de prediccion utilice los datos de prueba.

**Accuracy de todas las variables:**
```{r accuracy}
print(paste("schedtime",acc1$overall["Accuracy"]))
print(paste("carrier",acc2$overall["Accuracy"]))
# print(paste("deptime",acc3$overall["Accuracy"]))
print(paste("dest",acc4$overall["Accuracy"]))
print(paste("distance",acc5$overall["Accuracy"]))
print(paste("date",acc6$overall["Accuracy"]))
print(paste("flightnumber",acc7$overall["Accuracy"]))
print(paste("origin",acc8$overall["Accuracy"]))
print(paste("weather",acc9$overall["Accuracy"]))
print(paste("dayweek",acc10$overall["Accuracy"]))
print(paste("daymonth",acc11$overall["Accuracy"]))
print(paste("tailnu",acc12$overall["Accuracy"]))
```


```{r error}
print(paste("schedtime",1-acc1$overall["Accuracy"]))
print(paste("carrier",1-acc2$overall["Accuracy"]))
# print(paste("deptime",1-acc3$overall["Accuracy"]))
print(paste("dest",1-acc4$overall["Accuracy"]))
print(paste("distance",1-acc5$overall["Accuracy"]))
print(paste("date",1-acc6$overall["Accuracy"]))
print(paste("flightnumber",1-acc7$overall["Accuracy"]))
print(paste("origin",1-acc8$overall["Accuracy"]))
print(paste("weather",1-acc9$overall["Accuracy"]))
print(paste("dayweek",1-acc10$overall["Accuracy"]))
print(paste("daymonth",1-acc11$overall["Accuracy"]))
print(paste("tailnu",1-acc12$overall["Accuracy"]))
```


### d) Corra un modelo de bosque aleatorio con todas las variables.



```{r modelo_all,message=FALSE, warning=FALSE}
modelo = train(x=X_TRAIN,
y=Y_TRAIN,
method = "rf",
ntree = 100,
trControl = trainControl(method="cv",number=10))

```
### e) Determine el "accuracy" (ACC) del modelo ajustado. Utilice los datos de TEST.
```{r accuracy_all}
prediccion = predict(modelo,X_TEST)
acc=confusionMatrix(prediccion, Y_TEST)
acc

```
### f)  ?Cu?l es la probabilidad de que un vuelo con los datos: schedtime 840, carrier DL, dest LGA, distance 214, date 1/15/2004, flightnumber 4964, origin DCA, weather 0, dayweek 4, daymonth15, tailnu N703MQ, se retrase? 

```{r prediccion}

variables=data.frame(schedtime=as.integer(8),carrier="DL",dest="LGA", distance=214,date="1/15/2004", flightnumber=4964,
origin="DCA",weather=0, dayweek=0, daymonth=15,tailnu="N703MQ")
predict(modelo, newdata=variables,type = "prob")

```
0 El vuelo est? a tiempo.
1 El vuelo est? atrasado.

La probabilidad a que el vuelo se atrase es del 19%.

### h) Determine si el modelo encontrado en (d) tiene un menor o mayor ACC que el encontrado en (b). Utilice los datos de prueba.

```{r comparacion}
print(paste("modelo de weather",acc9$overall["Accuracy"]))
print(paste("modelo 11 variables",acc$overall["Accuracy"]))

```

### g) Considere que el costo de predecir un vuelo atrasado equivocadamente es la mitad que el de predecir un vuelo no atrasado equivocadamente. Determine el umbral de probabilidad ?ptimo en esta situaci?n.

```{r costo, message=FALSE, warning=FALSE}
prediccion_prob = predict(modelo, X_TEST, type="prob")
# prediccion_prob
umbral = 0.1
prediccion_clase = ifelse(prediccion_prob[,2]>umbral,1,0)
# prediccion_clase
#Umbral Ã³ptimo
umbral = seq(0,1,.001)
costo = NULL
costo_beta = 100
costo_alpha = 0.5*costo_beta
for (i in 1:length(umbral))
{
prediccion_clase = ifelse(prediccion_prob[,2]>umbral[i],1,0)
alpha = confusionMatrix(as.factor(prediccion_clase), Y_TEST)$table[1,2]
beta = confusionMatrix(as.factor(prediccion_clase), Y_TEST)$table[2,1]
costo[i]<-costo_alpha*alpha + costo_beta*beta
}
plot(umbral,costo,type = "h")
```



## Tema 2

**Importando los datos:**


```{r tema_2, message=FALSE, warning=FALSE}
dataset_tema_2 <-read_csv("/home/anthony/Documents/jc_IA/telecom_churn.csv")
dataset_tema_2<-na.omit(dataset_tema_2)
```

Por temas de practicidad primero proced? a realizar el literal b.
### b) Prepare los datos convirtiendo correctamente las variables en categ?ricas y en num?ricas.

**Categorizando las variables:**

```{r categorias}
dataset_tema_2[sapply(dataset_tema_2,is.character)] <- lapply(dataset_tema_2[sapply(dataset_tema_2, is.character)], as.factor)
```

## a) Particionar los datos en 70% en  entrenamiento y 30% para prueba.

```{r particion_2}
particion_2=createDataPartition(dataset_tema_2$Churn,p=0.7,list=FALSE,times=1)
X_TRAIN_2 = dataset_tema_2[particion_2,]
Y_TRAIN_2=X_TRAIN_2$Churn
X_TRAIN_2=subset(X_TRAIN_2,select=-c(customerID,Churn))

X_TEST_2 =dataset_tema_2[-particion_2,]
Y_TEST_2=X_TEST_2$Churn
X_TEST_2=subset(X_TEST_2,select=-c(customerID,Churn))
```
### c) Compararemos el desempe?o de los siguientes cuatro modelos de clasificaci?n: bayes ingenuo, ?rboles de clasificaci?n, bosques aleatorios, y regresi?n log?stica.

**Bayes ingenuo:**
```{r message=FALSE, warning=FALSE}
modelo <- train(x=X_TRAIN_2,y=Y_TRAIN_2,method="nb")

modelo

prediccion <- predict(modelo, X_TEST_2)




```
```{r}

confusionMatrix(prediccion,Y_TEST_2)


```
**?rboles de clasificaci?n:**

```{r message=FALSE, warning=FALSE}
modelo_2<- train(x=X_TRAIN_2,y=Y_TRAIN_2,method="rpart",trControl=trainControl(method='cv',
         number=10,summaryFunction=twoClassSummary,classProbs=TRUE,savePredictions=TRUE))

modelo_2



```

```{r}
prediccion_2 <- predict(modelo_2, X_TEST_2)

confusionMatrix(prediccion_2, Y_TEST_2)
```


**Bosques aleatorios:**
```{r message=FALSE, warning=FALSE}
XTRAIN_2=X_TRAIN_2

XTRAIN_2[sapply(XTRAIN_2,is.factor)] <- lapply(XTRAIN_2[sapply(XTRAIN_2, is.factor)], as.character)


modelo_3 <- train(x=na.omit(XTRAIN_2),y=na.omit(Y_TRAIN_2),method="rf",ntree=100,trControl=trainControl(method='cv',
               number=10,summaryFunction=twoClassSummary,classProbs=TRUE,savePredictions=TRUE))

modelo_3
```

```{r}

XTEST_2=X_TEST_2

XTEST_2[sapply(XTEST_2,is.factor)] <- lapply(XTEST_2[sapply(XTEST_2, is.factor)], as.character)

prediccion_3 <- predict(modelo_3, XTEST_2)

confusionMatrix(prediccion_3, Y_TEST_2)
```
**Regresi?n log?stica:**

```{r message=FALSE, warning=FALSE}
modelo_4 <-train(x=X_TRAIN_2,
                y=Y_TRAIN_2,
                method="glm",
                family="binomial",
                trControl=trainControl(method='cv',
                                       number=10,
                                       summaryFunction=twoClassSummary,
                                       classProbs=TRUE,
                                       savePredictions=TRUE))

modelo_4
```

```{r}
prediccion_4 <- predict(modelo_4, X_TEST_2)

confusionMatrix(prediccion_4, Y_TEST_2)
```

### d) Cree una tabla que compare el accuracy, specificity, y sensitivity para cada uno de los cuatro modelos de clasificaci?n. Para cada modelo, utilice la funci?n rfe del paquete caret para identifique el subconjunto ?ptimo de variables que producen el modelo con menor error de predicci?n.


```{r}
cm_T_2_m1<-confusionMatrix(prediccion,Y_TEST_2)
cm_T_2_m2<-confusionMatrix(prediccion_2, Y_TEST_2)
cm_T_2_m3<-confusionMatrix(prediccion_3, Y_TEST_2)
cm_T_2_m4<-confusionMatrix(prediccion_4, Y_TEST_2)
accuracy_all_models<-c(cm_T_2_m1$overall["Accuracy"],
                       cm_T_2_m2$overall["Accuracy"],
                       cm_T_2_m3$overall["Accuracy"],
                       cm_T_2_m4$overall["Accuracy"])

sensitive_all_model<-c(cm_T_2_m1$byClass["Sensitivity"],
                       cm_T_2_m2$byClass["Sensitivity"],
                       cm_T_2_m3$byClass["Sensitivity"],
                       cm_T_2_m4$byClass["Sensitivity"])

specifi_all_model<-c(cm_T_2_m1$byClass["Specificity"],
                       cm_T_2_m2$byClass["Specificity"],
                       cm_T_2_m3$byClass["Specificity"],
                       cm_T_2_m4$byClass["Specificity"])

names <- c("Bayes Ingenuo","Arboles de clasificaci?n","Bosques Aleatorios","Regresi?n Logistica")

comparacion<- cbind(names,round(accuracy_all_models,3),round(specifi_all_model,3),round(sensitive_all_model,3))
colnames(comparacion) <- c("Modelos","Accuracy","Specificity","Sensitivity")
rownames(comparacion) <- NULL
comparacion


```

```{r}

controlrfe<-rfeControl(functions = rfFuncs,method = "cv",number = 10)
results<-rfe(X_TRAIN_2,Y_TRAIN_2,sizes = c(1:19),rfeControl = controlrfe)
print(results)


```

```{r}
# predictor(results)
plot(results,type=c("g","o"))
```

Con 18 variables tiene mayor presici?n los modelos.

### e) Determine la selecci?n de modelo. Justifique su respuesta.
**Accuracy.**

En el an?lisis de los 4 modelos, el que tiene mayor precisi?n es el de Regresi?n log?stica con una medida de0.7917, continua el de Bosques Aleatorios con 0.7894, despu?s ?rbol de clasificaci?n con 0.7861 y para finalizar Bayes ingenuo con 0.759.

**Specificity.**

En el an?lisis de los 4 modelos, el que tiene mayor especificidad es Bayes ingenuo con una medida de 0.7750. Este valor es el complemento del error Tipo I, por lo tanto, la empresa descartar? consumidores que no romper?n la relaci?n comercial existente, lo cual afecta en una mayor cantidad a los recursos de la organizaci?n.

**Sensitivity.**

En el an?lisis de los 4 modelos, el modelo con mayor sensibilidad es el de ?rbol de Clasificaci?n con una probabilidad de 0.9386. Para esta medida a la organizaci?n debe de conocer el mayor valor de probabilidad, porque este indica que personas van a salir y que en el programa indique que si deben ser sacados.

**Conclusi?n.**

En base al an?lisis desarrollado, se concluye que el modelo ideal para que la organizaci?n de servicios de telecomunicaciones pueda predecir la probabilidad de deserci?n de sus consumidores, es el Bayes Ingenuo. Debido a que la organizaci?n tiene como objetivo disminuir el Error Tipo I, por lo tanto, deben de implementar un modelo de clasificaci?n que tenga la probabilidad de Specificity y Sensitivity mayor, a pesar que el Accuracy es el de menor valor a comparaci?n con los 3 modelos restantes, Bayes Ingenuo se posiciona como el modelo ganador debido que es el que cumple de mejor manera los requerimientos de la organizaci?n de telecomunicaciones.



